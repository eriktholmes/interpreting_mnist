# Interpretability applied to MNIST

‚ö†Ô∏è ***WARNING, WARNING, WARNING*** (Voiced by Kevin Malone) 

**This is a work in progress...**  This notebook is part of a live, educational build as I learn and explore interpretability tools from the ground up. It will be updated regularly with new experiments, edits, and insights. Suggestions and issues are always welcome!

## üí≠ What is it?
<!--This repo is part of my transition into machine learning, with a focus on interpretability and alignment. I have more legitimate interpretability project in mind but wanted to also start with the basics (hence MLP) where everything is simple and visualizations are easy to come by. I am also hoping for this to be somewhat educational for those on a similar path or looking to build some fun ML projects with interpretability options throughout. Like many of my projects, the primary goal here is to learn by building ‚Äî using hands-on experimentation/basic explainations to deepen my understanding (and hopefully help others!).-->
This repo is part of my transition into machine learning, with a focus on interpretability and alignment. I have more advanced, domain-relevant projects in mind ‚Äî but I wanted to begin with something fundamental: easy to visualize, easy to explain, and a natural continuation of my earlier **micrograd** build. 

> ENTER: The MLP on MNIST üòé

My goal here (and in general) is to learn by building, and to document the process in a way that's accessible to others on a similar path. If you're just getting started in ML or looking for hands-on ways to understand interpretability as you go, I hope this project is useful.

## üõ∏ Overview (for now):
Below is a list of things that I plan to do... but I also plan to write a fair deal as I go. 
- I'm training an MLP on MNIST using PyTorch (mirroring my earlier micrograd build).
- Along the way, I‚Äôm hoping to explore numerous interpretability tools: activation tracking, neuron behavior, PCA visualizations, and more.
- I‚Äôll then extend the model to a CNN, compare to MLP, and continue experimenting from there.
- The explanations are meant to be beginner-accessible but technically grounded ‚Äî let me know where/how I can improve!

  
